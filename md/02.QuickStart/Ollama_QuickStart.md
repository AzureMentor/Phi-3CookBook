# **Using Phi-3 in Ollama**

[Ollama](https://ollama.com) allows more people to directly deploy open source LLM or SLM through simple scripts, and can also build APIs to help local Copilot application scenarios.

## **1. Installation**

Ollama supports running on Windows, macOS, and Linux. You can install Ollama through this link ([https://ollama.com/download](https://ollama.com/download)). After successful installation, you can directly use Ollama script to call Phi-3 through a terminal window.


```bash

ollama run phi3

```

***Note:*** The model will be downloaded first when you run it for the first time. Of course, you can also directly specify the downloaded Phi-3 model. We take WSL as an example to run the command. After the model is successfully downloaded, you can interact directly on the terminal.

![run](../../imgs/02/Ollama/ollama_run.png)

## **2. Call the phi-3 API from Ollama**

If you want to call the Phi-3 API generated by ollama, you can use this command in the terminal

```bash

ollama serve

```
***Note:***  If running MacOS or Linux, please note that you may encounter the following error <b>"Error: listen tcp 127.0.0.1:11434: bind: address already in use"</b> You may get this error when calling running the command. The solution for this problems is:

**macOS**


```bash

brew services restart ollama

```

**Linux**


```bash

sudo systemctl stop ollama

```

Ollama supports two API: generate and chat. You can call the model API provided by Ollama according to your needs. Local service port 11434. such as

**Chat**

```bash

curl http://127.0.0.1:11434/api/chat -d '{
  "model": "phi3",
  "messages": [
    {
      "role": "system",
      "content": "Your are a python developer."
    },
    {
      "role": "user",
      "content": "Help me generate a bubble algorithm"
    }
  ],
  "stream": false
  
}'


```

This is the result in Postman


![chat](../../imgs/02/Ollama/ollama_chat.png)


```bash

curl http://127.0.0.1:11434/api/generate -d '{
  "model": "phi3",
  "prompt": "<|system|>Your are my AI assistant.<|end|><|user|>tell me how to learn AI<|end|><|assistant|>",
  "stream": false
}'


```


This is the result in Postman


![gen](../../imgs/02/Ollama/ollama_gen.png)


***Note:*** Visit this link [https://github.com/ollama/ollama/blob/main/docs/api.md](https://github.com/ollama/ollama/blob/main/docs/api.md) to learn more










